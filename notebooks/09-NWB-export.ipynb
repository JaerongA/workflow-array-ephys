{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15bdef0d-bd52-49e6-87a0-d569006149a0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# DataJoint U24 - Workflow Array Electrophysiology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad5b737",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, let's change directories to find the `dj_local_conf` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "921a4a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# change to the upper level folder to detect dj_local_conf.json\n",
    "if os.path.basename(os.getcwd())=='notebooks': os.chdir('..')\n",
    "assert os.path.basename(os.getcwd())=='workflow-array-ephys', (\"Please move to the \"\n",
    "                                                               + \"workflow directory\")\n",
    "# We'll be working with long tables, so we'll make visualization easier with a limit\n",
    "import datajoint as dj; dj.config['display.limit']=10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b2c6ae-b8cd-47b8-af38-812f65032933",
   "metadata": {},
   "source": [
    "If you haven't already populated the `lab`, `subject`, `session`, `probe`, and `ephys` schemas, please do so now with [04-automate](./04-automate-optional.ipynb). Note: exporting `ephys` data is currently only supported on the `no_curation` schema. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79cef246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting cbroz@dss-db.datajoint.io:3306\n"
     ]
    }
   ],
   "source": [
    "from workflow_array_ephys.pipeline import lab, subject, session, probe, ephys\n",
    "from workflow_array_ephys.export import (element_lab_to_nwb_dict, subject_to_nwb, \n",
    "                                         session_to_nwb, ecephys_session_to_nwb, \n",
    "                                         write_nwb)\n",
    "from element_interface.dandi import upload_to_dandi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafd4a7c",
   "metadata": {},
   "source": [
    "## Export to NWB\n",
    "\n",
    "Each of the following elements has tools for interacting with NWB files: `element-lab`, `element-session`, `element-array-ephys`, and `element-interface`. We'll use the following keys for testing these functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6cebd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_key={\"lab\": \"LabA\"}\n",
    "protocol_key={\"protocol\": \"ProtA\"}\n",
    "project_key={\"project\": \"ProjA\"}\n",
    "session_key={\"subject\": \"subject5\",\n",
    "             \"session_datetime\": \"2018-07-03 20:32:28\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2d028a",
   "metadata": {},
   "source": [
    "\n",
    "### Element Lab\n",
    "\n",
    "Because an NWB file must include session information, `element_lab_to_nwb_dict` can only help package information from the Lab schema into `dict` format. This would be helpful for a team using Element Lab, but not others. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6a3306b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function element_lab_to_nwb_dict in module element_lab.export.nwb:\n",
      "\n",
      "element_lab_to_nwb_dict(lab_key=None, project_key=None, protocol_key=None)\n",
      "    Generate a dictionary object containing all relevant lab information used\n",
      "        when generating an NWB file at the session level.\n",
      "        All parameters optional, but should only specify one of respective type\n",
      "    Use: mynwbfile = pynwb.NWBFile(identifier=\"your identifier\",\n",
      "                             session_description=\"your description\",\n",
      "                             session_start_time=session_datetime,\n",
      "                             **element_lab_to_nwb_dict(\n",
      "                                lab_key=key1,\n",
      "                                project_key=key2,\n",
      "                                protocol_key=key3))\n",
      "    \n",
      "    :param lab_key: Key specifying one entry in element_lab.lab.Lab\n",
      "    :param project_key: Key specifying one entry in element_lab.lab.Project\n",
      "    :param protocol_key: Key specifying one entry in element_lab.lab.Protocol\n",
      "    :return: dictionary with NWB parameters\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(element_lab_to_nwb_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61ba0714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'institution': 'Example Uni',\n",
       " 'lab': 'The Example Lab',\n",
       " 'experiment_description': 'Example project to populate element-lab',\n",
       " 'keywords': ['Example', 'Study'],\n",
       " 'related_publications': ['arXiv:1807.11104', 'arXiv:1807.11104v1'],\n",
       " 'protocol': 'ProtA',\n",
       " 'notes': 'Protocol for managing data ingestion'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "element_lab_to_nwb_dict(lab_key=lab_key, protocol_key=protocol_key, \n",
    "                        project_key=project_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66af900a",
   "metadata": {},
   "source": [
    "### Element Animal\n",
    "\n",
    "`subject_to_nwb` can use a session key to retrieve subject information, and will return an nwb file with a number of sections specified. When packaging into an NWB file, `pynwb` will display a warning regarding timezone information - datetime fields are assumed to be in local time, and will be converted to UTC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "71433b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cb/miniconda3/envs/ele/lib/python3.8/site-packages/pynwb/file.py:1037: UserWarning: Date is missing timezone information. Updating to local timezone.\n",
      "  warn(\"Date is missing timezone information. Updating to local timezone.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "subject pynwb.file.Subject at 0x140613566479040\n",
       "Fields:\n",
       "  date_of_birth: 2020-01-01 00:00:00-06:00\n",
       "  description: {\"subject\": \"subject5\", \"sex\": \"F\", \"subject_birth_date\": \"2020-01-01\", \"subject_description\": \"rich\", \"line\": null, \"strain\": null, \"source\": null}\n",
       "  sex: F\n",
       "  subject_id: subject5"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject_to_nwb(session_key=session_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d2c7e3",
   "metadata": {},
   "source": [
    "### Element Session\n",
    "\n",
    "`session_to_nwb` pulls the same information as above, while also including information about session experimenter and session time. The export process provides the same warning about timezone conversion to UTC.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cc1b52b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cb/miniconda3/envs/ele/lib/python3.8/site-packages/pynwb/file.py:1037: UserWarning: Date is missing timezone information. Updating to local timezone.\n",
      "  warn(\"Date is missing timezone information. Updating to local timezone.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "root pynwb.file.NWBFile at 0x140613434487232\n",
       "Fields:\n",
       "  experimenter: ['User1']\n",
       "  file_create_date: [datetime.datetime(2022, 5, 31, 13, 58, 25, 578725, tzinfo=tzlocal())]\n",
       "  identifier: 9d2131bb-5747-4bf1-95f0-4b24b54b1968\n",
       "  session_description: Successful data collection\n",
       "  session_id: subject5_2018-07-03T20:32:28\n",
       "  session_start_time: 2018-07-04 01:32:28+00:00\n",
       "  subject: subject pynwb.file.Subject at 0x140613566479712\n",
       "Fields:\n",
       "  date_of_birth: 2020-01-01 00:00:00-06:00\n",
       "  description: {\"subject\": \"subject5\", \"sex\": \"F\", \"subject_birth_date\": \"2020-01-01\", \"subject_description\": \"rich\", \"line\": null, \"strain\": null, \"source\": null}\n",
       "  sex: F\n",
       "  subject_id: subject5\n",
       "\n",
       "  timestamps_reference_time: 2018-07-04 01:32:28+00:00"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session_to_nwb(session_key=session_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5fba81",
   "metadata": {},
   "source": [
    "\n",
    "### Element Array Electrophysiology\n",
    "\n",
    "`ecephys_session_to_nwb` provides a full export mechanism, returning an NWB file with raw, data, spikes, and LFP. Optional arguments determine which pieces are exported. For demonstration purposes, we recommend limiting `end_frame`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c2f913c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function ecephys_session_to_nwb in module element_array_ephys.export.nwb.nwb:\n",
      "\n",
      "ecephys_session_to_nwb(session_key, raw=True, spikes=True, lfp='source', end_frame=None, lab_key=None, project_key=None, protocol_key=None, nwbfile_kwargs=None)\n",
      "    Main function for converting ephys data to NWB\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    session_key: dict\n",
      "    raw: bool\n",
      "        Whether to include the raw data from source. SpikeGLX and OpenEphys are supported\n",
      "    spikes: bool\n",
      "        Whether to include CuratedClustering\n",
      "    lfp:\n",
      "        \"dj\" - read LFP data from ephys.LFP\n",
      "        \"source\" - read LFP data from source (SpikeGLX supported)\n",
      "        False - do not convert LFP\n",
      "    end_frame: int, optional\n",
      "        Used to create small test conversions where large datasets are truncated.\n",
      "    lab_key, project_key, and protocol_key: dictionaries used to look up optional additional metadata\n",
      "    nwbfile_kwargs: dict, optional\n",
      "        - If element-session is not being used, this argument is required and must be a dictionary containing\n",
      "          'session_description' (str), 'identifier' (str), and 'session_start_time' (datetime),\n",
      "          the minimal data for instantiating an NWBFile object.\n",
      "    \n",
      "        - If element-session is being used, this argument can optionally be used to add over overwrite NWBFile fields.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ecephys_session_to_nwb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5edf9615",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cb/miniconda3/envs/ele/lib/python3.8/site-packages/pynwb/file.py:1037: UserWarning: Date is missing timezone information. Updating to local timezone.\n",
      "  warn(\"Date is missing timezone information. Updating to local timezone.\")\n",
      "creating units table for paramset 0: 100%|██████████| 499/499 [00:41<00:00, 12.11it/s]\n"
     ]
    }
   ],
   "source": [
    "nwbfile = ecephys_session_to_nwb(session_key=session_key,\n",
    "                                 raw=True,\n",
    "                                 spikes=True,\n",
    "                                 lfp=\"dj\",\n",
    "                                 end_frame=100,\n",
    "                                 lab_key=lab_key,\n",
    "                                 project_key=project_key,\n",
    "                                 protocol_key=protocol_key,\n",
    "                                 nwbfile_kwargs=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1131e149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "root pynwb.file.NWBFile at 0x140297891486016\n",
       "Fields:\n",
       "  acquisition: {\n",
       "    ElectricalSeries1 <class 'pynwb.ecephys.ElectricalSeries'>,\n",
       "    ElectricalSeries2 <class 'pynwb.ecephys.ElectricalSeries'>\n",
       "  }\n",
       "  devices: {\n",
       "    262716621 <class 'pynwb.device.Device'>,\n",
       "    714000838 <class 'pynwb.device.Device'>\n",
       "  }\n",
       "  electrode_groups: {\n",
       "    probe262716621_shank0 <class 'pynwb.ecephys.ElectrodeGroup'>,\n",
       "    probe714000838_shank0 <class 'pynwb.ecephys.ElectrodeGroup'>\n",
       "  }\n",
       "  electrodes: electrodes <class 'hdmf.common.table.DynamicTable'>\n",
       "  experiment_description: Example project to populate element-lab\n",
       "  experimenter: ['User1']\n",
       "  file_create_date: [datetime.datetime(2022, 5, 31, 15, 47, 41, 270996, tzinfo=tzlocal())]\n",
       "  identifier: 172f2d3b-44c1-4ae1-8785-2d20d3df3db1\n",
       "  institution: Example Uni\n",
       "  keywords: ['Example' 'Study']\n",
       "  lab: The Example Lab\n",
       "  notes: Protocol for managing data ingestion\n",
       "  processing: {\n",
       "    ecephys <class 'pynwb.base.ProcessingModule'>\n",
       "  }\n",
       "  protocol: ProtA\n",
       "  related_publications: ['arXiv:1807.11104' 'arXiv:1807.11104v1']\n",
       "  session_description: Successful data collection\n",
       "  session_id: subject5_2018-07-03T20:32:28\n",
       "  session_start_time: 2018-07-04 01:32:28+00:00\n",
       "  subject: subject pynwb.file.Subject at 0x140297891485200\n",
       "Fields:\n",
       "  date_of_birth: 2020-01-01 00:00:00-06:00\n",
       "  description: {\"subject\": \"subject5\", \"sex\": \"F\", \"subject_birth_date\": \"2020-01-01\", \"subject_description\": \"rich\", \"line\": null, \"strain\": null, \"source\": null}\n",
       "  sex: F\n",
       "  subject_id: subject5\n",
       "\n",
       "  timestamps_reference_time: 2018-07-04 01:32:28+00:00\n",
       "  units: units <class 'pynwb.misc.Units'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nwbfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6393fc",
   "metadata": {},
   "source": [
    "`write_nwb` can then be used to write this file to disk. The following cell will include a timestamp in the filename."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb3f1030",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from workflow_array_ephys.paths import get_ephys_root_data_dir\n",
    "    \n",
    "write_nwb(nwbfile, f'./temp_nwb/{time.strftime(\"_test_%Y%m%d-%H%M%S.nwb\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f717baf8",
   "metadata": {},
   "source": [
    "## DANDI Export\n",
    "\n",
    "`element-interface.dandi` includes the `upload_to_dandi` utility to support direct uploads. For more information, see [DANDI documentation](https://www.dandiarchive.org/handbook/10_using_dandi/).\n",
    "\n",
    "In order to upload, you'll need...\n",
    "1. A DANDI account\n",
    "2. A `DANDI_API_KEY`\n",
    "3. A `dandiset_id`\n",
    "\n",
    "These values can be added to your `dj.config` as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a75d1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dj.config['custom']['dandiset_id']=\"<six digits as string>\" \n",
    "dj.config['custom']['dandi.api']=\"<40-character alphanumeric string>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f65d15",
   "metadata": {},
   "source": [
    "This would facilitate routine updating of your dandiset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84dbce9f-825e-49a4-b49f-58b406873430",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A newer version (0.40.0) of dandi/dandi-cli is available. You are using 0.39.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PATH                 SIZE DONE    DONE% CHECKSUM STATUS MESSAGE   \n",
      "dandiset.yaml                                    done   updated   \n",
      "Summary:                  0 Bytes                1 done 1 updated \n",
      "                          <0.00%                                  \n"
     ]
    },
    {
     "ename": "FileExistsError",
     "evalue": "File './temp_nwb/200178/test1.nwb' already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_9/tzvq__ws5z9gv5s7jvkj570r0000gn/T/ipykernel_70901/2105288079.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m upload_to_dandi(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mdata_directory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"./temp_nwb/\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mdandiset_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'custom'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'dandiset_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mstaging\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mworking_directory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"./temp_nwb/\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/dev/element-interface/element_interface/dandi.py\u001b[0m in \u001b[0;36mupload_to_dandi\u001b[0;34m(data_directory, dandiset_id, staging, working_directory, api_key, sync)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mdandiset_directory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworking_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdandiset_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#enforce str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     download(\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0;34mf\"https://gui-staging.dandiarchive.org/#/dandiset/{dandiset_id}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstaging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ele/lib/python3.8/site-packages/dandi/download.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(urls, output_dir, format, existing, jobs, jobs_per_zarr, get_metadata, get_assets, sync)\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"pyout\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mrec\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgen_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m                 \u001b[0mout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ele/lib/python3.8/site-packages/dandi/download.py\u001b[0m in \u001b[0;36mdownload_generator\u001b[0;34m(parsed_url, output_path, assets_it, yield_generator_for_fields, existing, get_metadata, get_assets, jobs_per_zarr)\u001b[0m\n\u001b[1;32m    317\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"path\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myield_generator_for_fields\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_download_generator\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mresp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_download_generator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m                     \u001b[0;32myield\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ele/lib/python3.8/site-packages/dandi/download.py\u001b[0m in \u001b[0;36m_download_file\u001b[0;34m(downloader, path, toplevel_path, lock, size, mtime, existing, digests, digest_callback)\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0mannex_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoplevel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\".git\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"annex\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mexisting\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"error\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mFileExistsError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"File {path!r} already exists\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mexisting\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"skip\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0m_skip_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"already exists\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileExistsError\u001b[0m: File './temp_nwb/200178/test1.nwb' already exists"
     ]
    }
   ],
   "source": [
    "upload_to_dandi(\n",
    "    data_directory=\"./temp_nwb/\",\n",
    "    dandiset_id=dj.config['custom']['dandiset_id'],\n",
    "    staging=True,\n",
    "    working_directory=\"./temp_nwb/\",\n",
    "    api_key=dj.config['custom']['dandi.api'],\n",
    "    sync=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dd56de-ecf3-469b-8aed-e2484402bcdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "61456c693db5d9aa6731701ec9a9b08ab88a172bee0780139a3679beb166da16"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 ('ele')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
