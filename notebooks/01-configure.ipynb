{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15bdef0d-bd52-49e6-87a0-d569006149a0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# DataJoint configuration\n",
    "\n",
    "## Setup - Working Directory\n",
    "\n",
    "To run the array ephys workflow, we need to properly set up the DataJoint configuration. The configuration will be saved in a file called `dj_local_conf.json` on each machine and this notebook walks you through the process.\n",
    "\n",
    "**The configuration only needs to be set up once**, if you have gone through the configuration before, directly go to [02-workflow-structure](02-workflow-structure-optional.ipynb).\n",
    "\n",
    "As a convention, we set the configuration up in the root directory of the workflow package and always starts importing datajoint and pipeline modules from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2dc935",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change to the upper level folder\n",
    "if os.path.basename(os.getcwd()) == \"notebooks\":\n",
    "    os.chdir(\"..\")\n",
    "assert os.path.basename(os.getcwd()) == \"workflow-array-ephys\", (\n",
    "    \"Please move to the \" + \"workflow directory\"\n",
    ")\n",
    "import datajoint as dj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - Credentials\n",
    "\n",
    "Now let's set up the host, user and password in the `dj.config` global variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6820ef4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dj.config[\"database.host\"] = \"{YOUR_HOST}\"\n",
    "dj.config[\"database.user\"] = \"{YOUR_USERNAME}\"\n",
    "dj.config[\"database.password\"] = getpass.getpass()  # enter the password securily"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should be able to connect to the database at this stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dj.conn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup - `dj.config['custom']`\n",
    "\n",
    "The major component of the current workflow is the [DataJoint Array Ephys Element](https://github.com/datajoint/element-array-ephys). Array Ephys Element requires configurations in the field `custom` in `dj.config`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Database prefix\n",
    "\n",
    "Giving a prefix to schema could help on the configuration of privilege settings. For example, if we set prefix `neuro_`, every schema created with the current workflow will start with `neuro_`, e.g. `neuro_lab`, `neuro_subject`, `neuro_ephys` etc.\n",
    "\n",
    "The prefix could be configurated as follows in `dj.config`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dj.config[\"custom\"] = {\"database.prefix\": \"neuro_\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Root directories for raw/processed data\n",
    "\n",
    "`ephys_root_data_dir` field indicates the root directory for\n",
    "+ The **ephys raw data** from SpikeGLX or OpenEphys, including `*{.ap,lf}.{bin,meta}`\n",
    "+ The **clustering results** from kilosort2 (e.g. `spike_{times,clusters}.npy`\n",
    "\n",
    "The root path typically **do not** contain information of subjects or sessions, all data from subjects/sessions should be subdirectories in the root path.\n",
    "\n",
    "In the example dataset downloaded with [these instructions](00-data-download-optional.ipynb), `/tmp/test_data` will be the root\n",
    "\n",
    "```\n",
    "/tmp/test_data/\n",
    "- subject6\n",
    "    - session1\n",
    "        - towersTask_g0_imec0\n",
    "        - towersTask_g0_t0_nidq.meta\n",
    "        - towersTask_g0_t0.nidq.bin\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If there is only one root path.\n",
    "dj.config[\"custom\"][\"ephys_root_data_dir\"] = \"/tmp/test_data\"\n",
    "# If there are multiple possible root paths:\n",
    "dj.config[\"custom\"][\"ephys_root_data_dir\"] = [\"/tmp/test_data1\", \"/tmp/test_data2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dj.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7733450",
   "metadata": {},
   "outputs": [],
   "source": [
    "[markdown]\n",
    "# + In the database, every path for the ephys raw data is **relative to root path(s)**. The benefit is that the absolute path could be configured for each machine, and when data transfer happens, we just need to change the root directory in the config file.\n",
    "#\n",
    "# + The workflow supports **multiple root directories**. If there are multiple possible root directories, specify the `ephys_root_data_dir` as a list.\n",
    "#\n",
    "# + The root path(s) are **specific to each machine**, as the name of mounted drive could be different for different operating systems or machines.\n",
    "#\n",
    "# + In the context of the workflow, all the paths saved into the database or saved in the config file need to be in the **POSIX standards** (Unix/Linux), with `/`. The path conversion for machines of any operating system is taken care of inside the elements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e5b2ff",
   "metadata": {},
   "source": [
    "### Ephys Mode\n",
    "\n",
    "`element-array-ephys` offers 3 different schemas: `acute`, `chronic`, and `no-curation`. For more information about each, please visit the [electrophysiology description page](https://elements.datajoint.org/description/array_ephys/). This decision should be made before first activating the schema. Note: only `no-curation` is supported for export to NWB directly from the Element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d533d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dj.config[\"custom\"][\"ephys_mode\"] = \"no-curation\"  # or acute or chronic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940ea19a",
   "metadata": {},
   "source": [
    "## Save configuration\n",
    "\n",
    "With the proper configurations, we could save this as a file, either as a local json file, or a global file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc8b17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dj.config.save_local()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b95596f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76904b4",
   "metadata": {},
   "source": [
    "Local configuration file is saved as `dj_local_conf.json` in the root directory of this package `workflow-array-ephys`. Next time if you change your directory to `workflow-array-ephys` before importing datajoint and the pipeline packages, the configurations will get properly loaded.\n",
    "\n",
    "If saved globally, there will be a hidden configuration file saved in your root directory. The configuration will be loaded no matter where the directory is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dj.config.save_global()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the configuration, we will be able to review the workflow structure with [02-workflow-structure-optional](02-workflow-structure-optional.ipynb)."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py_scripts//py"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit ('python3p10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "ff52d424e56dd643d8b2ec122f40a2e279e94970100b4e6430cb9025a65ba4cf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
